{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-d26969165472>:27: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From c:\\users\\jeredriq\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From c:\\users\\jeredriq\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\users\\jeredriq\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From c:\\users\\jeredriq\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "# RESOURCES:\n",
    "# https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/2_BasicModels/random_forest.py\n",
    "# https://github.com/tensorflow/cleverhans/blob/master/cleverhans_tutorials/mnist_tutorial_tf.py\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.platform import flags\n",
    "\n",
    "from cleverhans.loss import CrossEntropy\n",
    "from cleverhans.dataset import MNIST\n",
    "from cleverhans.utils_tf import model_eval\n",
    "from cleverhans.train import train\n",
    "from cleverhans.attacks import FastGradientMethod\n",
    "from cleverhans.utils import AccuracyReport, set_log_level\n",
    "from cleverhans_tutorials.tutorial_models import ModelBasicCNN\n",
    "from tensorflow.contrib.tensor_forest.python import tensor_forest\n",
    "from tensorflow.python.ops import resources\n",
    "\n",
    "#Importing Mnist...\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS = flags.FLAGS\n",
    "\n",
    "NB_EPOCHS = 6\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.001\n",
    "CLEAN_TRAIN = True\n",
    "BACKPROP_THROUGH_ATTACK = False\n",
    "NB_FILTERS = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_tutorial(train_start=0, train_end=60000, test_start=0,\n",
    "                   test_end=10000, nb_epochs=NB_EPOCHS, batch_size=BATCH_SIZE,\n",
    "                   learning_rate=LEARNING_RATE,\n",
    "                   clean_train=CLEAN_TRAIN,\n",
    "                   testing=False,\n",
    "                   backprop_through_attack=BACKPROP_THROUGH_ATTACK,\n",
    "                   nb_filters=NB_FILTERS, num_threads=None,\n",
    "                   label_smoothing=0.1):\n",
    "  \"\"\"\n",
    "  MNIST cleverhans tutorial\n",
    "  :param train_start: index of first training set example\n",
    "  :param train_end: index of last training set example\n",
    "  :param test_start: index of first test set example\n",
    "  :param test_end: index of last test set example\n",
    "  :param nb_epochs: number of epochs to train model\n",
    "  :param batch_size: size of training batches\n",
    "  :param learning_rate: learning rate for training\n",
    "  :param clean_train: perform normal training on clean examples only\n",
    "                      before performing adversarial training.\n",
    "  :param testing: if true, complete an AccuracyReport for unit tests\n",
    "                  to verify that performance is adequate\n",
    "  :param backprop_through_attack: If True, backprop through adversarial\n",
    "                                  example construction process during\n",
    "                                  adversarial training.\n",
    "  :param label_smoothing: float, amount of label smoothing for cross entropy\n",
    "  :return: an AccuracyReport object\n",
    "  \"\"\"\n",
    "\n",
    "  # Object used to keep track of (and return) key accuracies\n",
    "  report = AccuracyReport()\n",
    "\n",
    "  # Set TF random seed to improve reproducibility\n",
    "  tf.set_random_seed(1234)\n",
    "\n",
    "  # Set logging level to see debug information\n",
    "  set_log_level(logging.DEBUG)\n",
    "\n",
    "  # Create TF session\n",
    "  if num_threads:\n",
    "    config_args = dict(intra_op_parallelism_threads=1)\n",
    "  else:\n",
    "    config_args = {}\n",
    "  sess = tf.Session(config=tf.ConfigProto(**config_args))\n",
    "\n",
    "\n",
    "   \n",
    "  # Parameters\n",
    "  num_steps = 500 # Total steps to train\n",
    "  batch_size = 1024 # The number of samples per batch\n",
    "  num_classes = 10 # The 10 digits\n",
    "  num_features = 784 # Each image is 28x28 pixels\n",
    "  num_trees = 10\n",
    "  max_nodes = 1000\n",
    "\n",
    "  # Input and Target data\n",
    "  X = tf.placeholder(tf.float32, shape=[None, num_features])\n",
    "  # For random forest, labels must be integers (the class id)\n",
    "  Y = tf.placeholder(tf.int32, shape=[None])\n",
    "\n",
    "  # Get MNIST data\n",
    "  mnistt = MNIST(train_start=train_start, train_end=train_end,\n",
    "                test_start=test_start, test_end=test_end)\n",
    "  x_train, y_train = mnistt.get_set('train')\n",
    "  x_test, y_test = mnistt.get_set('test')\n",
    "\n",
    "  # Use Image Parameters\n",
    "  img_rows, img_cols, nchannels = x_train.shape[1:4]\n",
    "  nb_classes = y_train.shape[1]\n",
    "\n",
    "\n",
    "  # Train an MNIST model\n",
    "  train_params = tensor_forest.ForestHParams(num_classes=num_classes,\n",
    "                                      num_features=num_features,\n",
    "                                      num_trees=num_trees,\n",
    "                                      max_nodes=max_nodes).fill()\n",
    "\n",
    "  # Build the Random Forest\n",
    "  forest_graph = tensor_forest.RandomForestGraphs(train_params)\n",
    "  # Get training graph and loss\n",
    "  train_op = forest_graph.training_graph(X, Y)\n",
    "  loss_op = forest_graph.training_loss(X, Y)\n",
    "  \n",
    "  # Measure the accuracy\n",
    "  infer_op, _, _ = forest_graph.inference_graph(X)\n",
    "  correct_prediction = tf.equal(tf.argmax(infer_op, 1), tf.cast(Y, tf.int64))\n",
    "  accuracy_op = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "  \n",
    "  # Initialize the variables (i.e. assign their default value) and forest resources\n",
    "  init_vars = tf.group(tf.global_variables_initializer(),\n",
    "      resources.initialize_resources(resources.shared_resources()))\n",
    "  \n",
    "  # Start TensorFlow session\n",
    "  sess = tf.Session()\n",
    "  \n",
    "  # Run the initializer\n",
    "  sess.run(init_vars)\n",
    "  \n",
    "  # Training\n",
    "  for i in range(1, num_steps + 1):\n",
    "      # Prepare Data\n",
    "      # Get the next batch of MNIST data (only images are needed, not labels)\n",
    "      batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "      _, l = sess.run([train_op, loss_op], feed_dict={X: batch_x, Y: batch_y})\n",
    "      if i % 50 == 0 or i == 1:\n",
    "          acc = sess.run(accuracy_op, feed_dict={X: batch_x, Y: batch_y})\n",
    "          print('Step %i, Loss: %f, Acc: %f' % (i, l, acc))\n",
    "            \n",
    "  #end randomforest\n",
    "\n",
    "  eval_params = {'batch_size': batch_size}\n",
    "  fgsm_params = {\n",
    "      'eps': 0.3,\n",
    "      'clip_min': 0.,\n",
    "      'clip_max': 1.\n",
    "  }\n",
    "  rng = np.random.RandomState([2017, 8, 30])\n",
    "\n",
    "  def do_eval(preds, x_set, y_set, report_key, is_adv=None):\n",
    "    acc = model_eval(sess, x, y, preds, x_set, y_set, args=eval_params)\n",
    "    setattr(report, report_key, acc)\n",
    "    if is_adv is None:\n",
    "      report_text = None\n",
    "    elif is_adv:\n",
    "      report_text = 'adversarial'\n",
    "    else:\n",
    "      report_text = 'legitimate'\n",
    "    if report_text:\n",
    "      print('Test accuracy on %s examples: %0.4f' % (report_text, acc))\n",
    "\n",
    "  if clean_train:\n",
    "    model = ModelBasicCNN('model1', nb_classes, nb_filters)\n",
    "    preds = model.get_logits(X)\n",
    "    loss = CrossEntropy(model, smoothing=label_smoothing)\n",
    "\n",
    "    def evaluate():\n",
    "      do_eval(preds, x_test, y_test, 'clean_train_clean_eval', False)\n",
    "\n",
    "    train(sess, loss, x_train, y_train, evaluate=evaluate,\n",
    "          args=train_params, rng=rng, var_list=model.get_params())\n",
    "\n",
    "    # Calculate training error\n",
    "    if testing:\n",
    "      do_eval(preds, x_train, y_train, 'train_clean_train_clean_eval')\n",
    "\n",
    "    # Initialize the Fast Gradient Sign Method (FGSM) attack object and\n",
    "    # graph\n",
    "    fgsm = FastGradientMethod(model, sess=sess)\n",
    "    adv_x = fgsm.generate(x, **fgsm_params)\n",
    "    preds_adv = model.get_logits(adv_x)\n",
    "\n",
    "    # Evaluate the accuracy of the MNIST model on adversarial examples\n",
    "    do_eval(preds_adv, x_test, y_test, 'clean_train_adv_eval', True)\n",
    "\n",
    "    # Calculate training error\n",
    "    if testing:\n",
    "      do_eval(preds_adv, x_train, y_train, 'train_clean_train_adv_eval')\n",
    "\n",
    "    print('Repeating the process, using adversarial training')\n",
    "\n",
    "  # Create a new model and train it to be robust to FastGradientMethod\n",
    "  model2 = ModelBasicCNN('model2', nb_classes, nb_filters)\n",
    "  fgsm2 = FastGradientMethod(model2, sess=sess)\n",
    "\n",
    "  def attack(x):\n",
    "    return fgsm2.generate(x, **fgsm_params)\n",
    "\n",
    "  loss2 = CrossEntropy(model2, smoothing=label_smoothing, attack=attack)\n",
    "  preds2 = model2.get_logits(x)\n",
    "  adv_x2 = attack(x)\n",
    "\n",
    "  if not backprop_through_attack:\n",
    "    # For the fgsm attack used in this tutorial, the attack has zero\n",
    "    # gradient so enabling this flag does not change the gradient.\n",
    "    # For some other attacks, enabling this flag increases the cost of\n",
    "    # training, but gives the defender the ability to anticipate how\n",
    "    # the atacker will change their strategy in response to updates to\n",
    "    # the defender's parameters.\n",
    "    adv_x2 = tf.stop_gradient(adv_x2)\n",
    "  preds2_adv = model2.get_logits(adv_x2)\n",
    "\n",
    "  def evaluate2():\n",
    "    # Accuracy of adversarially trained model on legitimate test inputs\n",
    "    do_eval(preds2, x_test, y_test, 'adv_train_clean_eval', False)\n",
    "    # Accuracy of the adversarially trained model on adversarial examples\n",
    "    do_eval(preds2_adv, x_test, y_test, 'adv_train_adv_eval', True)\n",
    "\n",
    "  # Perform and evaluate adversarial training\n",
    "  train(sess, loss2, x_train, y_train, evaluate=evaluate2,\n",
    "        args=train_params, rng=rng, var_list=model2.get_params())\n",
    "\n",
    "  # Calculate training errors\n",
    "  if testing:\n",
    "    do_eval(preds2, x_train, y_train, 'train_adv_train_clean_eval')\n",
    "    do_eval(preds2_adv, x_train, y_train, 'train_adv_train_adv_eval')\n",
    "\n",
    "  return report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Constructing forest with params = \n",
      "INFO:tensorflow:{'feature_bagging_fraction': 1.0, 'valid_leaf_threshold': 1, 'prune_every_samples': 0, 'max_fertile_nodes': 0, 'bagging_fraction': 1.0, 'regression': False, 'param_file': None, 'dominate_method': 'bootstrap', 'early_finish_check_every_samples': 0, 'num_trees': 10, 'num_outputs': 1, 'stats_model_type': 0, 'max_nodes': 1000, 'num_classes': 10, 'num_splits_to_consider': 28, 'bagged_features': None, 'split_type': 0, 'num_output_columns': 11, 'pruning_type': 0, 'bagged_num_features': 784, 'model_name': 'all_dense', 'split_name': 'less_or_equal', 'checkpoint_stats': False, 'leaf_model_type': 0, 'base_random_seed': 0, 'num_features': 784, 'split_after_samples': 250, 'inference_tree_paths': False, 'finish_type': 0, 'dominate_fraction': 0.99, 'split_finish_name': 'basic', 'use_running_stats_method': False, 'split_pruning_name': 'none', 'initialize_average_splits': False, 'collate_examples': False}\n",
      "Step 1, Loss: -1.000000, Acc: 0.393555\n",
      "Step 50, Loss: -253.000000, Acc: 0.886719\n",
      "Step 100, Loss: -539.200012, Acc: 0.911133\n",
      "Step 150, Loss: -824.200012, Acc: 0.911133\n",
      "Step 200, Loss: -1001.000000, Acc: 0.923828\n",
      "Step 250, Loss: -1001.000000, Acc: 0.916016\n",
      "Step 300, Loss: -1001.000000, Acc: 0.912109\n",
      "Step 350, Loss: -1001.000000, Acc: 0.933594\n",
      "Step 400, Loss: -1001.000000, Acc: 0.914062\n",
      "Step 450, Loss: -1001.000000, Acc: 0.930664\n",
      "Step 500, Loss: -1001.000000, Acc: 0.915039\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer conv2d_4 is incompatible with the layer: expected ndim=4, found ndim=2. Full shape received: [None, 784]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-a55f5fcc597b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m                      'construction process during adversarial training'))\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m   \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\jeredriq\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(main, argv)\u001b[0m\n\u001b[0;32m    123\u001b[0m   \u001b[1;31m# Call the main function, passing through any arguments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m   \u001b[1;31m# to the final program.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m   \u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-a55f5fcc597b>\u001b[0m in \u001b[0;36mmain\u001b[1;34m(argv)\u001b[0m\n\u001b[0;32m      9\u001b[0m                  \u001b[0mclean_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclean_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m                  \u001b[0mbackprop_through_attack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackprop_through_attack\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m                  nb_filters=FLAGS.nb_filters)\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-340d81a0b10b>\u001b[0m in \u001b[0;36mmnist_tutorial\u001b[1;34m(train_start, train_end, test_start, test_end, nb_epochs, batch_size, learning_rate, clean_train, testing, backprop_through_attack, nb_filters, num_threads, label_smoothing)\u001b[0m\n\u001b[0;32m    130\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mclean_train\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModelBasicCNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_filters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m     \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_logits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCrossEntropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msmoothing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabel_smoothing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jeredriq\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\cleverhans\\model.py\u001b[0m in \u001b[0;36mget_logits\u001b[1;34m(self, x, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0mfed\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0minputs\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msoftmax\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m     \"\"\"\n\u001b[1;32m---> 65\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfprop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mO_LOGITS\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mO_LOGITS\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jeredriq\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\cleverhans_tutorials\\tutorial_models.py\u001b[0m in \u001b[0;36mfprop\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m     36\u001b[0m         kernel_initializer=initializers.HeReLuNormalInitializer)\n\u001b[0;32m     37\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreuse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAUTO_REUSE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m       \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmy_conv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnb_filters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'same'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m       \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmy_conv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnb_filters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'valid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m       \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmy_conv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnb_filters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'valid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jeredriq\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\layers\\convolutional.py\u001b[0m in \u001b[0;36mconv2d\u001b[1;34m(inputs, filters, kernel_size, strides, padding, data_format, dilation_rate, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, trainable, name, reuse)\u001b[0m\n\u001b[0;32m    415\u001b[0m       \u001b[0m_reuse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreuse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m       _scope=name)\n\u001b[1;32m--> 417\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jeredriq\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    815\u001b[0m       \u001b[0mOutput\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m     \"\"\"\n\u001b[1;32m--> 817\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    819\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_set_learning_phase_metadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jeredriq\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    372\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    373\u001b[0m       \u001b[1;31m# Actually call layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 374\u001b[1;33m       \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jeredriq\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m         \u001b[1;31m# Check input assumptions set before layer building, e.g. input rank.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 730\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_assert_input_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    731\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minput_list\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    732\u001b[0m           \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jeredriq\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_assert_input_compatibility\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   1475\u001b[0m                            \u001b[1;34m'expected ndim='\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m', found ndim='\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1476\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'. Full shape received: '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1477\u001b[1;33m                            str(x.shape.as_list()))\n\u001b[0m\u001b[0;32m   1478\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1479\u001b[0m         \u001b[0mndim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndims\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 of layer conv2d_4 is incompatible with the layer: expected ndim=4, found ndim=2. Full shape received: [None, 784]"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def main(argv=None):\n",
    "  from cleverhans_tutorials import check_installation\n",
    "  #check_installation(__file__)\n",
    "\n",
    "  mnist_tutorial(nb_epochs=FLAGS.nb_epochs, batch_size=FLAGS.batch_size,\n",
    "                 learning_rate=FLAGS.learning_rate,\n",
    "                 clean_train=FLAGS.clean_train,\n",
    "                 backprop_through_attack=FLAGS.backprop_through_attack,\n",
    "                 nb_filters=FLAGS.nb_filters)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  flags.DEFINE_integer('nb_filters', NB_FILTERS,\n",
    "                       'Model size multiplier')\n",
    "  flags.DEFINE_integer('nb_epochs', NB_EPOCHS,\n",
    "                       'Number of epochs to train model')\n",
    "  flags.DEFINE_integer('batch_size', BATCH_SIZE,\n",
    "                       'Size of training batches')\n",
    "  flags.DEFINE_float('learning_rate', LEARNING_RATE,\n",
    "                     'Learning rate for training')\n",
    "  flags.DEFINE_bool('clean_train', CLEAN_TRAIN, 'Train on clean examples')\n",
    "  flags.DEFINE_bool('backprop_through_attack', BACKPROP_THROUGH_ATTACK,\n",
    "                    ('If True, backprop through adversarial example '\n",
    "                     'construction process during adversarial training'))\n",
    "\n",
    "  tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
